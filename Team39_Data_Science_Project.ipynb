{"cells":[{"cell_type":"markdown","id":"62aed769","metadata":{"id":"62aed769"},"source":["### 1. Introduction: Project Overview\n","\n","This project centers around the comprehensive analysis of three distinct datasets: movie Data, critic reviews, and user reviews. The scope of the project encompasses various aspects, including:\n","\n","- Data Cleaning: Ensuring data integrity and quality for accurate analysis.\n","- Data Analysis: Identifying and evaluating the best movies based on various metrics.\n","- Data Visualization: Creating insightful visual representations of the data to facilitate understanding.\n","- Linear Regression: Applying statistical methods to predict audience scores based on relevant features.\n","- Natural Language Processing (NLP): Analyzing textual data from reviews to extract meaningful insights.\n","\n","Below are the summarized details of the three datasets presented in their respective dictionaries:"]},{"cell_type":"markdown","id":"c6614996","metadata":{"id":"c6614996"},"source":["#### Data Dictionary for `Movies`\n","\n","| Column Name               | Data Type | Description                                                                                           |\n","| ------------------------- | --------- | ----------------------------------------------------------------------------------------------------- |\n","| `movieId`                 | object    | Unique identifier for each movie.                                                                     |\n","| `movieYear`               | int64     | The year the movie was released.                                                                      |\n","| `movieURL`                | object    | URL to the movie's page on Rotten Tomatoes.                                                           |\n","| `movieTitle`              | object    | The title of the movie.                                                                               |\n","| `critic_score`            | float64   | Average score given by critics for the movie.                                                         |\n","| `critic_sentiment`        | object    | Sentiment of the critic's reviews (e.g., positive, negative, neutral).                                 |\n","| `audience_score`          | float64   | Average score given by audience members for the movie.                                                |\n","| `audience_sentiment`      | object    | Sentiment of audience reviews (e.g., positive, negative, neutral).                                     |\n","| `release_date_theaters`   | object    | The release date of the movie in theaters.                                                            |\n","| `release_date_streaming`  | object    | The release date of the movie on streaming platforms.                                                 |\n","| `rating`                  | object    | The movie's rating (e.g., PG, PG-13, R).                                                              |\n","| `original_language`       | object    | The original language of the movie (e.g., English, French).                                           |\n","| `runtime`                 | object    | The runtime of the movie in minutes (may be stored as text in some cases, e.g., \"120 minutes\").       |\n","\n","<br/>\n","\n","#### Data Dictionary for `Critic Reviews`\n","\n","| Column Name         | Data Type | Description                                                                                           |\n","| ------------------- | --------- | ----------------------------------------------------------------------------------------------------- |\n","| `reviewId`          | int64     | Unique identifier for each critic review.                                                             |\n","| `movieId`           | object    | Unique identifier for the movie that the review corresponds to.                                        |\n","| `creationDate`      | object    | The date when the review was created or published.                                                     |\n","| `criticName`        | object    | The name of the critic who wrote the review.                                                           |\n","| `criticPageUrl`     | object    | URL to the critic's page on Rotten Tomatoes or the publication website.                                |\n","| `reviewState`       | object    | The state of the review (e.g., published, draft).                                                      |\n","| `isFresh`           | bool      | A boolean indicator whether the review is categorized as \"Fresh\" (positive review).                    |\n","| `isRotten`          | bool      | A boolean indicator whether the review is categorized as \"Rotten\" (negative review).                   |\n","| `isRtUrl`           | object    | URL to the Rotten Tomatoes page for this review (if available).                                        |\n","| `isTopCritic`       | bool      | A boolean indicator whether the review was written by a \"Top Critic\" on Rotten Tomatoes.               |\n","| `publicationUrl`    | object    | URL to the publication's homepage or the article containing the review.                                |\n","| `publicationName`   | object    | The name of the publication where the review was published.                                            |\n","| `reviewUrl`         | object    | Direct URL to the individual review page on the publication's website.                                 |\n","| `quote`             | object    | A brief excerpt or quote from the review.                                                              |\n","| `scoreSentiment`    | object    | The sentiment of the review (e.g., positive, negative).                                                |\n","| `originalScore`     | object    | The original score given by the critic, if available.                                |\n","\n","<br/>\n","\n","#### Data Dictionary for `User Reviews`\n","\n","| Column Name        | Data Type | Description                                                                                           |\n","| ------------------ | --------- | ----------------------------------------------------------------------------------------------------- |\n","| `movieId`          | object    | Unique identifier for the movie that the user review corresponds to.                                   |\n","| `rating`           | float64   | The rating given by the user, typically a score between 0 and 10 (or similar scale).                   |\n","| `quote`            | object    | A brief excerpt or comment from the user's review.                                                     |\n","| `reviewId`         | object    | Unique identifier for each user review.                                                                |\n","| `isVerified`       | bool      | A boolean indicating whether the user who wrote the review is a verified user.                         |\n","| `isSuperReviewer`  | bool      | A boolean indicating whether the user is marked as a \"Super Reviewer\" (frequent and/or trusted user).  |\n","| `hasSpoilers`      | bool      | A boolean indicating whether the review contains spoilers.                                             |\n","| `hasProfanity`     | bool      | A boolean indicating whether the review contains profanity.                                            |\n","| `score`            | float64   | The score given by the user (if different from `rating`).                                              |\n","| `creationDate`     | object    | The date when the user review was created or published.                                                |\n","| `userDisplayName`  | object    | The display name of the user who wrote the review.                                                     |\n","| `userRealm`        | object    | The region or realm associated with the user (could be location-based information).                    |\n","| `userId`           | object    | Unique identifier for the user who wrote the review.                                                   |\n"]},{"cell_type":"markdown","id":"c24c07b4","metadata":{"id":"c24c07b4"},"source":["### 2. Importing Libraries and Loading Data\n","To start our analysis, we import the necessary libraries for data manipulation, visualization, and natural language processing (NLP). Libraries such as Pandas, Matplotlib, Seaborn, NLTK, and Scikit-learn provide powerful tools for handling our datasets.\n","\n","We then load three CSV files containing movie details, critic reviews, and user reviews into separate DataFrames. This is the foundation for our analysis and will allow us to combine different perspectives on movies."]},{"cell_type":"code","execution_count":1,"id":"e3d01c10","metadata":{"id":"e3d01c10","executionInfo":{"status":"ok","timestamp":1728831629615,"user_tz":-120,"elapsed":25587,"user":{"displayName":"M.M.","userId":"16283090766959631234"}}},"outputs":[],"source":["import os\n","import gdown\n","import pandas as pd\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","import plotly.express as px\n","from sklearn.linear_model import LinearRegression\n","from sklearn.metrics import mean_squared_error, r2_score, classification_report, confusion_matrix\n","from sklearn.model_selection import train_test_split\n","from sklearn.preprocessing import OneHotEncoder\n","from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n","from sklearn.ensemble import RandomForestClassifier\n","from textblob import TextBlob\n","from tqdm import tqdm\n","import nltk\n","import time\n","import ast\n","from nltk import pos_tag\n","from collections import Counter\n","import gc\n","from nltk.tokenize import word_tokenize\n","from wordcloud import WordCloud, STOPWORDS\n","from nltk.corpus import stopwords\n","from wordcloud import WordCloud\n","import spacy\n","import plotly.graph_objects as go"]},{"cell_type":"code","source":["# Load in smaller chunks instead of all at once\n","def download_and_load_csv_in_chunks(file_id, filename, chunk_size=10000, low_memory=True, dtype=None):\n","    url = f'https://drive.google.com/uc?export=download&id={file_id}'\n","    gdown.download(url, filename, quiet=True)\n","\n","    # Use chunksize to load in small portions\n","    df_chunks = pd.read_csv(filename, low_memory=low_memory, dtype=dtype, chunksize=chunk_size)\n","\n","    # Combine chunks to process them incrementally\n","    return pd.concat(df_chunks, ignore_index=True)\n","\n","# Google Drive file IDs\n","file_ids = {\n","    'movies': '19lYJrl5eTUCyBa0rieheC4i5sIIOlotz',\n","    'critic_reviews': '10XvJsU0vT8KK9-krIutzTMFN1NCGrXVD',\n","    'user_reviews': '1nFDc_qCWm0AxJfGy653LMycMvUt7K-B3'\n","}\n","\n","# Now load using the chunked approach\n","movies = download_and_load_csv_in_chunks(file_ids['movies'], 'movies.csv', chunk_size=10000, low_memory=False)\n","critic_reviews = download_and_load_csv_in_chunks(file_ids['critic_reviews'], 'critic_reviews.csv',\n","                                                    chunk_size=10000, low_memory=False, dtype={'isRtUrl': 'boolean'})\n","user_reviews = download_and_load_csv_in_chunks(file_ids['user_reviews'], 'sampled_user_reviews.csv',\n","                                                  chunk_size=10000, low_memory=False)\n","print(\"Datasets loaded successfully in chunks.\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":703},"id":"H5bYoap52CK2","executionInfo":{"status":"error","timestamp":1728831674076,"user_tz":-120,"elapsed":44462,"user":{"displayName":"M.M.","userId":"16283090766959631234"}},"outputId":"d2f276a7-8c58-4eb6-9a04-b555156dd23f"},"id":"H5bYoap52CK2","execution_count":2,"outputs":[{"output_type":"error","ename":"FileURLRetrievalError","evalue":"Failed to retrieve file url:\n\n\tToo many users have viewed or downloaded this file recently. Please\n\ttry accessing the file again later. If the file you are trying to\n\taccess is particularly large or is shared with many people, it may\n\ttake up to 24 hours to be able to view or download the file. If you\n\tstill can't access a file after 24 hours, contact your domain\n\tadministrator.\n\nYou may still be able to access the file from the browser:\n\n\thttps://drive.google.com/uc?export=download&id=1nFDc_qCWm0AxJfGy653LMycMvUt7K-B3\n\nbut Gdown can't. Please check connections and permissions.","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mFileURLRetrievalError\u001b[0m                     Traceback (most recent call last)","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/gdown/download.py\u001b[0m in \u001b[0;36mdownload\u001b[0;34m(url, output, quiet, proxy, speed, use_cookies, verify, id, fuzzy, resume, format, user_agent, log_messages)\u001b[0m\n\u001b[1;32m    266\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 267\u001b[0;31m             \u001b[0murl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_url_from_gdrive_confirmation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mres\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    268\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mFileURLRetrievalError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/gdown/download.py\u001b[0m in \u001b[0;36mget_url_from_gdrive_confirmation\u001b[0;34m(contents)\u001b[0m\n\u001b[1;32m     52\u001b[0m             \u001b[0merror\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroups\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mFileURLRetrievalError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merror\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     54\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mFileURLRetrievalError\u001b[0m: Too many users have viewed or downloaded this file recently. Please try accessing the file again later. If the file you are trying to access is particularly large or is shared with many people, it may take up to 24 hours to be able to view or download the file. If you still can't access a file after 24 hours, contact your domain administrator.","\nDuring handling of the above exception, another exception occurred:\n","\u001b[0;31mFileURLRetrievalError\u001b[0m                     Traceback (most recent call last)","\u001b[0;32m<ipython-input-2-37951981759f>\u001b[0m in \u001b[0;36m<cell line: 23>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     21\u001b[0m critic_reviews = download_and_load_csv_in_chunks(file_ids['critic_reviews'], 'critic_reviews.csv',\n\u001b[1;32m     22\u001b[0m                                                     chunk_size=10000, low_memory=False, dtype={'isRtUrl': 'boolean'})\n\u001b[0;32m---> 23\u001b[0;31m user_reviews = download_and_load_csv_in_chunks(file_ids['user_reviews'], 'sampled_user_reviews.csv', \n\u001b[0m\u001b[1;32m     24\u001b[0m                                                   chunk_size=10000, low_memory=False)\n\u001b[1;32m     25\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Datasets loaded successfully in chunks.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-2-37951981759f>\u001b[0m in \u001b[0;36mdownload_and_load_csv_in_chunks\u001b[0;34m(file_id, filename, chunk_size, low_memory, dtype)\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mdownload_and_load_csv_in_chunks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchunk_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlow_memory\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0murl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mf'https://drive.google.com/uc?export=download&id={file_id}'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mgdown\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdownload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mquiet\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;31m# Use chunksize to load in small portions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/gdown/download.py\u001b[0m in \u001b[0;36mdownload\u001b[0;34m(url, output, quiet, proxy, speed, use_cookies, verify, id, fuzzy, resume, format, user_agent, log_messages)\u001b[0m\n\u001b[1;32m    276\u001b[0m                 \u001b[0murl_origin\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    277\u001b[0m             )\n\u001b[0;32m--> 278\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mFileURLRetrievalError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    279\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    280\u001b[0m     \u001b[0mfilename_from_url\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mFileURLRetrievalError\u001b[0m: Failed to retrieve file url:\n\n\tToo many users have viewed or downloaded this file recently. Please\n\ttry accessing the file again later. If the file you are trying to\n\taccess is particularly large or is shared with many people, it may\n\ttake up to 24 hours to be able to view or download the file. If you\n\tstill can't access a file after 24 hours, contact your domain\n\tadministrator.\n\nYou may still be able to access the file from the browser:\n\n\thttps://drive.google.com/uc?export=download&id=1nFDc_qCWm0AxJfGy653LMycMvUt7K-B3\n\nbut Gdown can't. Please check connections and permissions."]}]},{"cell_type":"markdown","id":"84c91026","metadata":{"id":"84c91026"},"source":["## 3. Data cleaning"]},{"cell_type":"markdown","id":"d57a958d","metadata":{"id":"d57a958d"},"source":["### 3.1. Data Cleaning Functions\n","\n","**\"Camel Case to Snake Case Conversion\" Function**\n","\n","To ensure consistency, we convert column names from camelCase to snake_case using a function called camel_to_snake_manual(). This helps standardize column names for easier analysis and reference.\n","\n","**\"Standardizing Scores\" Function**\n","\n","The standardize_score() function is used to convert different score formats into a uniform scale (from 0 to 10). This allows us to compare scores across critics and users fairly.\n","\n","**\"Converting Runtime\" Function**\n","\n","The convert_runtime_to_minutes() function converts runtime values from hours and minutes format into total minutes. This ensures that runtime information is in a consistent and comparable numerical format."]},{"cell_type":"code","execution_count":null,"id":"d28edf24","metadata":{"id":"d28edf24","executionInfo":{"status":"aborted","timestamp":1728831674077,"user_tz":-120,"elapsed":9,"user":{"displayName":"M.M.","userId":"16283090766959631234"}}},"outputs":[],"source":["def camel_to_snake_manual(name):\n","    result = [name[0].lower()]\n","    for char in name[1:]:\n","        if char.isupper():\n","            result.append('_')\n","            result.append(char.lower())\n","        else:\n","            result.append(char)\n","    return ''.join(result)\n","\n","def standardize_score(score):\n","    try:\n","        if '/' in score:\n","            num, denom = map(float, score.split('/'))\n","            return round((num / denom) * 10, 1)\n","        else:\n","            return float(score)\n","    except:\n","        return np.nan\n","\n","def convert_runtime_to_minutes(runtime):\n","    if isinstance(runtime, str):\n","        hours, minutes = 0, 0\n","        if 'h' in runtime:\n","            parts = runtime.split('h')\n","            hours = int(parts[0].strip()) * 60\n","            if 'm' in parts[1]:\n","                minutes = int(parts[1].strip('m').strip())\n","        elif 'm' in runtime:\n","            minutes = int(runtime.strip('m').strip())\n","        return hours + minutes\n","    return None\n","\n","print(\"Cleaning functions defined.\")"]},{"cell_type":"markdown","id":"f47f925c","metadata":{"id":"f47f925c"},"source":["### 3.2. Cleaning Movie Data\n","The clean_movies() function cleans the movie dataset by:\n","\n","- Dropping unnecessary columns (e.g., URLs).\n","- Converting column names to snake_case.\n","- Handling missing values for scores, sentiments, and runtime.\n","- Extracting the release year from different date formats.\n","- Standardizing the language categories for consistency.\n","\n","The clean_movies() function encompasses among other thing the three functions previously built: \"camel_to_snake_manual\", \"standardize_score\" and \"convert_runtime_to_minutes\".\n","\n","The goal is to create a clean and usable dataset ready for merging and further analysis."]},{"cell_type":"code","execution_count":null,"id":"5e8e6886","metadata":{"id":"5e8e6886","executionInfo":{"status":"aborted","timestamp":1728831674077,"user_tz":-120,"elapsed":8,"user":{"displayName":"M.M.","userId":"16283090766959631234"}}},"outputs":[],"source":["def clean_movies(df):\n","    df_cleaned = df.copy()\n","    df_cleaned = df_cleaned.drop(columns='movieURL')\n","    df_cleaned.columns = [camel_to_snake_manual(col) for col in df_cleaned.columns]\n","\n","    # Fill missing scores and sentiments\n","    df_cleaned['critic_score'].fillna(df_cleaned['critic_score'].mean(), inplace=True)\n","    df_cleaned['audience_score'].fillna(df_cleaned['audience_score'].mean(), inplace=True)\n","    df_cleaned['critic_sentiment'].fillna('unknown', inplace=True)\n","    df_cleaned['audience_sentiment'].fillna('unknown', inplace=True)\n","    df_cleaned['rating'].fillna('unknown', inplace=True)\n","\n","    # Extract release years\n","    def extract_year(date_string):\n","        try:\n","            return pd.to_datetime(date_string, format='%Y-%m-%d', errors='coerce').year\n","        except:\n","            try:\n","                return pd.to_datetime(date_string, format='%B %d, %Y', errors='coerce').year\n","            except:\n","                return pd.NaT\n","\n","    df_cleaned['release_year_theaters'] = df_cleaned['release_date_theaters'].apply(extract_year)\n","    df_cleaned['release_year_streaming'] = df_cleaned['release_date_streaming'].apply(extract_year)\n","    df_cleaned = df_cleaned.drop(columns=['release_date_theaters', 'release_date_streaming'])\n","\n","    # Round scores\n","    df_cleaned['critic_score'] = df_cleaned['critic_score'].round(1)\n","    df_cleaned['audience_score'] = df_cleaned['audience_score'].round(1)\n","\n","    # Standardize language\n","    language_mapping = {\n","        'English (United Kingdom)': 'English',\n","        'English (Australia)': 'English',\n","        'British English': 'English',\n","        'Australian English': 'English',\n","        'Portuguese (Brazil)': 'Portuguese',\n","        'Brazilian Portuguese': 'Portuguese',\n","        'French (France)': 'French',\n","        'French (Canada)': 'French',\n","        'Canadian French': 'French',\n","        'Unknown language': 'Unknown'\n","    }\n","    df_cleaned['original_language'] = df_cleaned['original_language'].replace(language_mapping)\n","    df_cleaned['original_language'].fillna('Unknown', inplace=True)\n","\n","    # Convert runtime to minutes\n","    df_cleaned['runtime_in_minutes'] = df_cleaned['runtime'].apply(convert_runtime_to_minutes)\n","    df_cleaned = df_cleaned.drop(columns='runtime')\n","\n","    return df_cleaned\n","\n","movies_cleaned = clean_movies(movies)\n","print(\"Movies data cleaned.\")"]},{"cell_type":"markdown","source":["### 3.3. Cleaning Critic Reviews\n","The clean_critic_reviews() function:\n","\n","- Drops irrelevant columns.\n","- Converts the creation date to a year format.\n","- Handles missing values and filters out placeholder quotes that are not meaningful.\n","- Converts critic scores to a standardized range of 1 to 10.\n","\n","This helps in getting more meaningful data about critics' opinions and ensuring that only relevant quotes and reviews are retained."],"metadata":{"id":"zBauoJPZCp_0"},"id":"zBauoJPZCp_0"},{"cell_type":"code","source":["def clean_critic_reviews(df):\n","    df_cleaned = df.copy()\n","    df_cleaned.columns = [camel_to_snake_manual(col) for col in df_cleaned.columns]\n","\n","    columns_to_remove = ['critic_page_url', 'review_state', 'is_rotten', 'is_rt_url', 'publication_url', 'review_url']\n","    df_cleaned = df_cleaned.drop(columns=columns_to_remove)\n","\n","    df_cleaned['creation_date'] = pd.to_datetime(df_cleaned['creation_date'], errors='coerce')\n","    df_cleaned['creation_year'] = df_cleaned['creation_date'].dt.year\n","    df_cleaned = df_cleaned.drop(columns=['creation_date'])\n","\n","    df_cleaned['critic_name'] = df_cleaned['critic_name'].fillna('Unknown Critic')\n","    df_cleaned = df_cleaned.dropna(subset=['quote'])\n","    df_cleaned = df_cleaned.drop_duplicates(subset=['review_id'], keep='first')\n","\n","    placeholders = [\"full review at Movies for the Masses\", \"full review in Greek\", \".\",\n","                    \"click for full review\", \"Click to read review\", \"click to read full review\",\n","                    \"See website for more details.\", \"click to read the full review\", \"(No quote available.)\"]\n","    df_cleaned = df_cleaned[~df_cleaned['quote'].isin(placeholders)]\n","    df_cleaned = df_cleaned[df_cleaned['quote'].str.len() > 5]\n","\n","    df_cleaned['standardized_score'] = df_cleaned['original_score'].apply(standardize_score)\n","    mean_score = df_cleaned['standardized_score'].mean()\n","    df_cleaned['standardized_score'] = df_cleaned['standardized_score'].fillna(round(mean_score))\n","    df_cleaned['standardized_score'] = df_cleaned['standardized_score'].apply(lambda x: min(max(round(x), 1), 10))\n","\n","    df_cleaned = df_cleaned.drop(columns=['original_score'])\n","\n","    return df_cleaned\n","\n","critic_reviews_cleaned = clean_critic_reviews(critic_reviews)\n","print(\"Critic reviews cleaned.\")"],"metadata":{"id":"p04FxCF9Ci30","executionInfo":{"status":"aborted","timestamp":1728831674077,"user_tz":-120,"elapsed":8,"user":{"displayName":"M.M.","userId":"16283090766959631234"}}},"id":"p04FxCF9Ci30","execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### 3.4. Cleaning User Reviews\n","The clean_user_reviews() function cleans the user reviews by removing irrelevant columns, standardizing scores, and converting dates to a consistent year format. This is necessary for combining user feedback effectively with critic reviews and movie details.\n"],"metadata":{"id":"iLD9n0H6C5Sb"},"id":"iLD9n0H6C5Sb"},{"cell_type":"code","source":["def clean_user_reviews(df):\n","    df_cleaned = df.copy()\n","    df_cleaned = df_cleaned.drop(['reviewId', 'userDisplayName', 'isVerified', 'hasSpoilers', 'userRealm', 'hasProfanity', 'isSuperReviewer', 'rating'], axis=1)\n","\n","    df_cleaned.columns = [camel_to_snake_manual(col) for col in df_cleaned.columns]\n","\n","    def standardize_score(score):\n","        return min(10, max(1, round(score * 2)))\n","\n","    df_cleaned['standardized_score'] = df_cleaned['score'].apply(standardize_score)\n","\n","    df_cleaned['creation_date'] = pd.to_datetime(df_cleaned['creation_date'], errors='coerce')\n","    df_cleaned['creation_year'] = df_cleaned['creation_date'].dt.year\n","    df_cleaned = df_cleaned.drop(columns=['creation_date'])\n","\n","    return df_cleaned\n","\n","sampled_user_reviews_cleaned = clean_user_reviews(user_reviews)\n","print(\"User reviews cleaned.\")"],"metadata":{"id":"r6mTqIbnC5gt","executionInfo":{"status":"aborted","timestamp":1728831674077,"user_tz":-120,"elapsed":9,"user":{"displayName":"M.M.","userId":"16283090766959631234"}}},"id":"r6mTqIbnC5gt","execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### 3.5. Merging Datasets\n","We merged the three cleaned datasets (movies, critic reviews, and user reviews) using the merge_datasets() function. This function:\n","\n","- Aggregates critic and user reviews to calculate average scores.\n","- Combines quotes from both critics and users.\n","- Keeps existing sentiments from the original movie dataset.\n","\n","This comprehensive dataset provides a complete picture, combining both critic and user perspectives on each movie."],"metadata":{"id":"biPMI9XBCjDC"},"id":"biPMI9XBCjDC"},{"cell_type":"code","execution_count":null,"id":"e1d9fde5","metadata":{"id":"e1d9fde5","executionInfo":{"status":"aborted","timestamp":1728831674078,"user_tz":-120,"elapsed":9,"user":{"displayName":"M.M.","userId":"16283090766959631234"}}},"outputs":[],"source":["movies_cleaned[[\"movie_title\",\"rating\"]]"]},{"cell_type":"code","execution_count":null,"id":"baad8b17","metadata":{"id":"baad8b17","executionInfo":{"status":"aborted","timestamp":1728831674078,"user_tz":-120,"elapsed":9,"user":{"displayName":"M.M.","userId":"16283090766959631234"}}},"outputs":[],"source":["# Count the occurrences of \"Unknown\" and \"unknown\" in the 'rating' column of movies_clean\n","rating_counts = movies_cleaned['rating'].value_counts()\n","\n","# Extract counts for \"Unknown\" and \"unknown\"\n","count_unknown = rating_counts.get(\"Unknown\", 0)  # Returns 0 if \"Unknown\" is not found\n","count_unknown_lower = rating_counts.get(\"unknown\", 0)  # Returns 0 if \"unknown\" is not found\n","\n","# Display the results\n","print(f\"Count of 'Unknown': {count_unknown}\")\n","print(f\"Count of 'unknown': {count_unknown_lower}\")\n"]},{"cell_type":"markdown","id":"219186a2","metadata":{"id":"219186a2"},"source":["## 4. Data Analysis of the movies data <br/>\n","\n","This section shows the data analysis and the corresponding data visualization for each of the following parts:<br/>\n","\n","- \"Most popular movies of all time\"<br/>\n","- \"Most popular 100 movies by critic score\"<br/>\n","- \"Most popular 100 movies by combined critic & audience score\".<br/>\n","\n","For this part of the project the clean dataframe called \"movies_cleaned\" will be used."]},{"cell_type":"markdown","id":"03463e92","metadata":{"id":"03463e92"},"source":["### 4.1. Most popular 100 movies of all time\n","To identify the 100 most popular movies of all time, we used audience_score as respresentative of popularity, ranked them and listed the top 100."]},{"cell_type":"code","source":["# most popular movie based on the audience score\n","\n","pd.set_option('display.max_rows', 100)\n","\n","top_100_movies = movies_cleaned.sort_values(by=['audience_score', 'movie_year'], ascending=[False, True]).head(100)\n","\n","top_100_movies[['movie_title', 'audience_score', 'movie_year']]"],"metadata":{"id":"L2noD1DecHb5","executionInfo":{"status":"aborted","timestamp":1728831674078,"user_tz":-120,"elapsed":9,"user":{"displayName":"M.M.","userId":"16283090766959631234"}}},"id":"L2noD1DecHb5","execution_count":null,"outputs":[]},{"cell_type":"markdown","id":"cf10f685","metadata":{"id":"cf10f685"},"source":["### 4.2. Most popular 100 movies by critic score\n"]},{"cell_type":"code","execution_count":null,"id":"c12e6f23","metadata":{"id":"c12e6f23","executionInfo":{"status":"aborted","timestamp":1728831674078,"user_tz":-120,"elapsed":9,"user":{"displayName":"M.M.","userId":"16283090766959631234"}}},"outputs":[],"source":["# Sort the movies based on critic score and movie year, and get the top 100\n","top_100_movies = movies_cleaned.sort_values(by=['critic_score', 'movie_year'], ascending=[False, True]).head(100)\n","\n","# Define 10-year bins and create a new column to group movie years by decade\n","bins = range(1900, 2030, 10)  # 10-year bins\n","labels = [f'{b}-{b+9}' for b in bins[:-1]]  # Create labels for the bins\n","\n","# Create a new column 'decade' in top_100_movies to categorize movies into 10-year intervals\n","top_100_movies['decade'] = pd.cut(top_100_movies['movie_year'], bins=bins, labels=labels, right=False)\n","\n","# Count the number of movies in each decade\n","decade_counts = top_100_movies['decade'].value_counts().sort_index()\n","\n","# Set global parameters for text anti-aliasing and sharpness\n","plt.rcParams['text.antialiased'] = True\n","plt.rcParams['figure.dpi'] = 150  # Increase DPI for better text sharpness\n","\n","# Set up the figure with high DPI for sharper text\n","plt.figure(figsize=(14, 8))  # Increased figure size for better display\n","\n","# Plot a bar plot with Seaborn for separated bars\n","ax = sns.barplot(x=decade_counts.index, y=decade_counts.values, edgecolor='black', color='#1f77b4')  # Original blue color\n","\n","# Set titles and labels with anti-aliasing enabled by default, add pad to title for spacing\n","plt.title('Distribution of the Most Popular 100 Movies by Critic Score (Grouped by Decade)', fontsize=16, pad=20)  # Adjust the pad value for distance\n","plt.xlabel('Decade', fontsize=12)\n","plt.ylabel('Number of Movies', fontsize=12)\n","\n","# Remove the top spine (frame line above the plot)\n","ax.spines['top'].set_visible(False)\n","ax.spines[\"right\"].set_visible(False)\n","\n","# Add numbers above each bar\n","for index, value in enumerate(decade_counts.values):\n","    plt.text(index, value + 0.5, str(value), ha='center', fontsize=10)\n","\n","# Adjust the layout for better presentation\n","plt.tight_layout()\n","\n","# Show the plot\n","plt.show()"]},{"cell_type":"code","source":["# Get the top 100 most popular movies based on critic_score\n","top_100_movies_critic_score = movies_cleaned.nlargest(100, 'critic_score')\n","\n","# Create year bins/intervals for every 10 years (including \"1910-1919\")\n","bins = [1900, 1910, 1920, 1930, 1940, 1950, 1960, 1970, 1980, 1990, 2000, 2010, 2020]\n","labels = ['1900-1909', '1910-1919', '1920-1929', '1930-1939', '1940-1949', '1950-1959',\n","          '1960-1969', '1970-1979', '1980-1989', '1990-1999', '2000-2009', '2010-2019']\n","\n","# Bin the movie years into intervals, even if a bin is empty\n","top_100_movies_critic_score['year_interval'] = pd.cut(top_100_movies_critic_score['movie_year'], bins=bins, labels=labels, right=False)\n","\n","# Create a new DataFrame to consolidate movie titles by year interval, sorted by year\n","hover_data = top_100_movies_critic_score.groupby('year_interval', observed=False).apply(\n","    lambda x: '<br>• '.join(sorted([f\"{title} ({year})\" for title, year in zip(x['movie_title'], x['movie_year'])], key=lambda y: int(y.split('(')[-1][:-1])))).reset_index(name='movie_title_list')\n","\n","# Ensure the first movie title in each hover starts with a bullet point\n","hover_data['movie_title_list'] = '• ' + hover_data['movie_title_list']\n","\n","# Merge back to include movie titles in the main DataFrame\n","top_100_movies_critic_score = top_100_movies_critic_score.merge(hover_data, on='year_interval', suffixes=('', '_list'), how='right')\n","\n","# Create the bar plot\n","fig = px.bar(\n","    top_100_movies_critic_score,\n","    x='year_interval',\n","    y='critic_score',  # This is just a dummy to create the bars, it doesn't matter\n","    color_discrete_sequence=['green'],\n","    hover_name='year_interval',\n","    hover_data={'movie_title_list': True},  # Show the list of movie titles on hover\n","    title='Top 100 Movies by Critic Score (Interactive Graph)',\n","    labels={'year_interval': 'Year Interval', 'critic_score': 'Movies Count'}\n",")\n","\n","# Customize hover to show movie titles and other desired info\n","fig.update_traces(hovertemplate='Movies with best critic score (from past to present):<br><br>%{customdata[0]}')\n","\n","# Remove y-axis labels since they aren't meaningful here\n","fig.update_layout(yaxis_title='', yaxis=dict(showticklabels=False))\n","\n","# Center the title and add the message below it with a small distance from the graph\n","fig.update_layout(\n","    title_x=0.5,  # Center the title\n","    annotations=[\n","        dict(\n","            text=\"All these movies have been rated 100 by the critic. The graph shows these movies grouped by decade.<br>Go with the mouse on a bar to see the list of movies.\",\n","            xref=\"paper\", yref=\"paper\",\n","            x=0.5, y=1.1,  # Slightly increased 'y' to add space between text and graph\n","            showarrow=False,\n","            font=dict(size=12),  # Increased font size\n","            align=\"center\"\n","        )\n","    ],\n","    xaxis=dict(tickfont=dict(size=10))  # Adjust the font size of x-axis labels (decades)\n",")\n","\n","# Show the plot\n","fig.show()"],"metadata":{"id":"qHxwSgVcIKes","executionInfo":{"status":"aborted","timestamp":1728831674078,"user_tz":-120,"elapsed":9,"user":{"displayName":"M.M.","userId":"16283090766959631234"}}},"id":"qHxwSgVcIKes","execution_count":null,"outputs":[]},{"cell_type":"markdown","id":"70a345fc","metadata":{"id":"70a345fc"},"source":["### 4.3. Top 100 movies by \"combined critic & audience score\""]},{"cell_type":"code","execution_count":null,"id":"42a40db7","metadata":{"id":"42a40db7","executionInfo":{"status":"aborted","timestamp":1728831674078,"user_tz":-120,"elapsed":9,"user":{"displayName":"M.M.","userId":"16283090766959631234"}}},"outputs":[],"source":["# Calculate the combined score as the average of critic_score and audience_score\n","movies_cleaned['combined_score'] = (movies_cleaned['critic_score'] + movies_cleaned['audience_score']) / 2\n","\n","# Get the top 100 movies based on the combined score\n","top_100_combined_score = movies_cleaned.nlargest(100, 'combined_score')\n","\n","# Create a new DataFrame to consolidate movie titles by combined score\n","hover_data = top_100_combined_score.groupby('combined_score').apply(\n","    lambda x: '<br>• '.join(sorted([f\"{title} ({year})\" for title, year in zip(x['movie_title'], x['movie_year'])], key=lambda y: int(y.split('(')[-1][:-1])))\n",").reset_index(name='movie_title_list')\n","\n","# Merge back to include movie titles in the main DataFrame\n","top_100_combined_score = top_100_combined_score.merge(hover_data, on='combined_score')\n","\n","# Create the scatter plot\n","fig = px.scatter(\n","    top_100_combined_score,\n","    x='combined_score',\n","    y='combined_score',  # Dummy y-value for the dots\n","    hover_name='combined_score',\n","    hover_data={'movie_title_list': True},  # Show the list of movie titles\n","    title='Top 100 Movies by Combined Critic and Audience Score (interactive graph)',\n","    size='combined_score',  # Size based on the combined score\n","    size_max=20,  # Adjust the size of the dots\n",")\n","\n","# Update hover template to show bullet points with a line break\n","fig.update_traces(hovertemplate='Movie titles (from past to present):<br><br>• %{customdata[0]}')\n","\n","# Center the title\n","fig.update_layout(title_x=0.5)\n","\n","# Remove Y-axis as it is not meaningful\n","fig.update_layout(yaxis_title='', yaxis=dict(showticklabels=False))\n","\n","# Show the plot\n","fig.show()"]},{"cell_type":"markdown","id":"4b18fc5a","metadata":{"id":"4b18fc5a"},"source":["## 5. Data Science Methods\n","In this chapter, we delve into the application of two widely recognized and powerful data science methodologies: Multiple Linear Regression and Natural Language Processing (NLP). These techniques have been instrumental in extracting deeper insights from the datasets of the project."]},{"cell_type":"markdown","id":"357efa76","metadata":{"id":"357efa76"},"source":["## 5.1. Multiple Linear Regression\n","Multiple Linear Regression is a statistical approach used to model the relationship between multiple independent variables and a dependent variable. This method enables the identification and quantification of the influence of various factors on a particular outcome, thereby providing valuable insights into the underlying patterns within the data. By employing Multiple Linear Regression, significant relationships can be uncovered that enhance the understanding of trends and predictions in the movie industry.\n","<br/>\n","<br/>\n","For the development of the linear regression model, only variables from the \"movies\" dataset were utilized. To facilitate this process, a copy of the \"movies_cleaned\" DataFrame was created, ensuring that the original data remained intact while allowing for the necessary analyses to be conducted. Variables from the \"critic reviews\" and \"user reviews\" datasets were excluded from this analysis."]},{"cell_type":"code","execution_count":null,"id":"86a0c129","metadata":{"id":"86a0c129","executionInfo":{"status":"aborted","timestamp":1728831674078,"user_tz":-120,"elapsed":9,"user":{"displayName":"M.M.","userId":"16283090766959631234"}}},"outputs":[],"source":["# create a copy of the movies_cleaned dataset\n","movies_cleaned2 = movies_cleaned.copy()"]},{"cell_type":"markdown","id":"1d1d149d","metadata":{"id":"1d1d149d"},"source":["For our model we will use the following variables:\n","- \"audience_score\" as dependent variable;\n","- \"rating\",\"runtime_in_minutes\" and \"original_language\" as independent variables. Before building the linear regression model the following variables need some adjustments:\n","\n","- rating\n","\n","- runtime_in_minutes\n","\n","- original_language\n","\n","For example, the variable \"rating\" has 2475 \"Unknown\" values. For simplicity we drop the rows with this rating value:"]},{"cell_type":"code","source":["# Let's find out how many rows of the column Rating have Unknown in them\n","unknown_count = movies_cleaned2[movies_cleaned2['rating'] == 'unknown'].shape[0]\n","\n","print(f'Number of rows with \"unknown\" rating: {unknown_count}')"],"metadata":{"id":"R6UU_BDGbq6g","executionInfo":{"status":"aborted","timestamp":1728831674078,"user_tz":-120,"elapsed":9,"user":{"displayName":"M.M.","userId":"16283090766959631234"}}},"execution_count":null,"outputs":[],"id":"R6UU_BDGbq6g"},{"cell_type":"code","source":["# Remove rows where the 'rating' column contains the string 'Unknown' in movies_cleaned2 dataset\n","movies_cleaned2 = movies_cleaned2[movies_cleaned2['rating'] != 'unknown']\n","print(f'Number of rows with \"unknown\" rating: {unknown_count}')"],"metadata":{"id":"M586KIbGrzoQ","executionInfo":{"status":"aborted","timestamp":1728831674078,"user_tz":-120,"elapsed":9,"user":{"displayName":"M.M.","userId":"16283090766959631234"}}},"execution_count":null,"outputs":[],"id":"M586KIbGrzoQ"},{"cell_type":"markdown","source":["Now let's focus on the \"runtime_in_minutes\" column, which has some irrelevant values too:"],"metadata":{"id":"86d2eea7"},"id":"86d2eea7"},{"cell_type":"code","execution_count":null,"id":"5f5e5791","metadata":{"id":"5f5e5791","executionInfo":{"status":"aborted","timestamp":1728831674078,"user_tz":-120,"elapsed":9,"user":{"displayName":"M.M.","userId":"16283090766959631234"}}},"outputs":[],"source":["# Find out how many rows of the column runtime_in_minutes is missing or non-numerical\n","\n","missing_count = movies_cleaned2['runtime_in_minutes'].isna().sum()\n","\n","# Count rows where 'runtime_in_minutes' is non-numerical\n","non_numeric_count = pd.to_numeric(movies_cleaned2['runtime_in_minutes'], errors='coerce').isna().sum()\n","\n","# Exclude the NaN values from the non-numerical count (if they're already counted as missing)\n","non_numeric_only = non_numeric_count - missing_count\n","\n","print(f'Number of missing (NaN) values in \"runtime_in_minutes\": {missing_count}')\n","print(f'Number of non-numerical values in \"runtime_in_minutes\": {non_numeric_only}')"]},{"cell_type":"markdown","source":["Let's print the movie_titles with missing runtime_in_minutes:\n"],"metadata":{"id":"0YGH0R8OzNH3"},"id":"0YGH0R8OzNH3"},{"cell_type":"code","execution_count":null,"id":"438f99f5","metadata":{"id":"438f99f5","executionInfo":{"status":"aborted","timestamp":1728831674078,"user_tz":-120,"elapsed":9,"user":{"displayName":"M.M.","userId":"16283090766959631234"}}},"outputs":[],"source":["\n","# Filter rows where 'runtime_in_minutes' is missing (NaN)\n","missing_runtime_movies_cleaned2 = movies_cleaned2[movies_cleaned2['runtime_in_minutes'].isna()]\n","\n","# Select and display relevant columns: movie_title, movie_year, runtime_in_minutes\n","missing_runtime_info = missing_runtime_movies_cleaned2[['movie_title', 'movie_year', 'runtime_in_minutes']]\n","\n","# Show the rows with missing runtime information\n","print(missing_runtime_info)"]},{"cell_type":"markdown","source":["Next is to fill this missing runtime_in_minutes with accurate values:\n","\n","\n","\n"],"metadata":{"id":"vlFjWsWnzkBN"},"id":"vlFjWsWnzkBN"},{"cell_type":"code","execution_count":null,"id":"43d96e27","metadata":{"id":"43d96e27","executionInfo":{"status":"aborted","timestamp":1728831674078,"user_tz":-120,"elapsed":9,"user":{"displayName":"M.M.","userId":"16283090766959631234"}}},"outputs":[],"source":["# We will create a dictionary with movie titles, years, and their correct runtimes\n","runtime_updates = {\n","\n","    ('Quasi', 2023): 100\n","}\n","\n","# Update the runtime_in_minutes column\n","for (title, year), runtime in runtime_updates.items():\n","    movies_cleaned2.loc[(movies_cleaned2['movie_title'] == title) & (movies_cleaned2['movie_year'] == year), 'runtime_in_minutes'] = runtime\n","\n","movies_cleaned2_relevant = movies_cleaned2[['movie_title', 'movie_year', 'runtime_in_minutes']]\n","\n","# Verify the changes\n","print(movies_cleaned2_relevant[movies_cleaned2_relevant['runtime_in_minutes'].isna() == False].loc[movies_cleaned2['movie_title'].isin([title for title, year in runtime_updates])])"]},{"cell_type":"markdown","source":["Now we will fix the data in the column \"original_language\" by inserting the missing language for the rows with missing or \"Unknown\" value:"],"metadata":{"id":"CwPorB0i0GvF"},"id":"CwPorB0i0GvF"},{"cell_type":"code","execution_count":null,"id":"95eb573b","metadata":{"id":"95eb573b","executionInfo":{"status":"aborted","timestamp":1728831674079,"user_tz":-120,"elapsed":9,"user":{"displayName":"M.M.","userId":"16283090766959631234"}}},"outputs":[],"source":["# Check for missing and \"Unknown\" values in the 'original_language' column\n","missing_values = movies_cleaned2['original_language'].isnull().sum()\n","\n","# To find out how many rows of the column original_language have Unknown in them\n","unknown_count = movies_cleaned2[movies_cleaned2['original_language'] == 'Unknown'].shape[0]\n","\n","\n","print(f\"Number of missing values in 'original_language': {missing_values}\")\n","print(f\"Number of rows with 'Unknown' in 'original_language': {unknown_count}\")"]},{"cell_type":"code","execution_count":null,"id":"c6445c8c","metadata":{"scrolled":false,"id":"c6445c8c","executionInfo":{"status":"aborted","timestamp":1728831674079,"user_tz":-120,"elapsed":9,"user":{"displayName":"M.M.","userId":"16283090766959631234"}}},"outputs":[],"source":["# Obtain list of movies where 'original_language' is 'Unknown'\n","unknown_languages = movies_cleaned2[movies_cleaned2['original_language'] == 'Unknown']\n","\n","# Extract the list of movie titles where original_language is 'Unknown'\n","movie_titles_with_unknown_language = unknown_languages[['movie_title','original_language']].values.tolist()\n","\n","# Output the list\n","movie_titles_with_unknown_language"]},{"cell_type":"code","execution_count":null,"id":"a2648d94","metadata":{"id":"a2648d94","executionInfo":{"status":"aborted","timestamp":1728831674079,"user_tz":-120,"elapsed":9,"user":{"displayName":"M.M.","userId":"16283090766959631234"}}},"outputs":[],"source":["# Dictionary mapping movie titles to their original languages\n","\n","language_mapping = {\n","    \"Adam Sandler: 100% Fresh\": \"English\",\n","    \"Apocalypto\": \"Yucatec Maya\",\n","    \"Bo Burnham: Make Happy\": \"English\",\n","    \"City Lights\": \"Nonverbal\",\n","    \"Hannah Gadsby: Nanette\": \"English\",\n","    \"Out of Darkness\": \"Tola\",  # Fictitious language\n","    \"The Artist\": \"French\",\n","    \"The Red Turtle\": \"Nonverbal\"\n","}\n","\n","\n","\n","# Update the original_language column based on the mapping\n","movies_cleaned2['original_language'] = movies_cleaned2['movie_title'].map(language_mapping).fillna(movies_cleaned2['original_language'])\n","\n","# Check for missing values in the 'original_language' column\n","missing_values = movies_cleaned2['original_language'].isnull().sum()\n","\n","# To find out how many rows of the column original_language have Unknown in them\n","unknown_count = movies_cleaned2[movies_cleaned2['original_language'] == 'Unknown'].shape[0]\n","\n","\n","print(f\"Number of missing values in 'original_language': {missing_values}\")\n","print(f\"Number of rows with 'Unknown' in 'original_language': {unknown_count}\")\n","print(\"'original_language' column is filled.\")"]},{"cell_type":"markdown","source":["Our next step is to convert any columns of our interest that contain strings into categories. Once we can do that, we can apply one-hot encoding to convert categorical data into a numeric format that can be used for our regression model"],"metadata":{"id":"w1RjvCI6PU3e"},"id":"w1RjvCI6PU3e"},{"cell_type":"code","source":["# Which columns contain strings?\n","# These columns contain strings\n","for label, content in movies_cleaned2.items():\n","    if pd.api.types.is_string_dtype(content):\n","        print(label)"],"metadata":{"id":"kj5mmDLasp7U","executionInfo":{"status":"aborted","timestamp":1728831674079,"user_tz":-120,"elapsed":9,"user":{"displayName":"M.M.","userId":"16283090766959631234"}}},"execution_count":null,"outputs":[],"id":"kj5mmDLasp7U"},{"cell_type":"code","source":["# List of columns that need to be converted to category dtype for our regression model\n","columns_to_convert = ['rating', 'original_language']\n","\n","# Loop through the dataframe columns\n","for label, content in movies_cleaned2.items():\n","    if label in columns_to_convert and pd.api.types.is_string_dtype(content):\n","        movies_cleaned2[label] = content.astype(\"category\").cat.as_ordered()\n","\n","# Verify the change\n","print(movies_cleaned2.dtypes)"],"metadata":{"id":"AhW67WoI4UNh","executionInfo":{"status":"aborted","timestamp":1728831674079,"user_tz":-120,"elapsed":9,"user":{"displayName":"M.M.","userId":"16283090766959631234"}}},"execution_count":null,"outputs":[],"id":"AhW67WoI4UNh"},{"cell_type":"markdown","source":["### 5.1.1. Defining the baseline variables before applying the \"one-hot encoding\" method"],"metadata":{"id":"uY48pbny1suL"},"id":"uY48pbny1suL"},{"cell_type":"code","source":["# Check the frequency of each category in the 'rating' column\n","rating_counts = movies_cleaned2['rating'].value_counts()\n","\n","# Print the most common rating\n","most_common_rating = rating_counts.idxmax()\n","\n","print(f\"The most common rating is: {most_common_rating}\")"],"metadata":{"id":"bI4Z-ycdebHc","executionInfo":{"status":"aborted","timestamp":1728831674079,"user_tz":-120,"elapsed":9,"user":{"displayName":"M.M.","userId":"16283090766959631234"}}},"execution_count":null,"outputs":[],"id":"bI4Z-ycdebHc"},{"cell_type":"markdown","source":["So R rating will be our baseline to compare every category in rating with"],"metadata":{"id":"otseZRfLfhjQ"},"id":"otseZRfLfhjQ"},{"cell_type":"code","source":["# Check the frequency of each category in the 'original_language' column\n","original_language_counts = movies_cleaned2['original_language'].value_counts()\n","\n","# Print the most common rating\n","most_common_original_language = original_language_counts.idxmax()\n","\n","print(f\"The most common original_language is: {most_common_original_language}\")"],"metadata":{"id":"TnRouNuGgbtN","executionInfo":{"status":"aborted","timestamp":1728831674079,"user_tz":-120,"elapsed":9,"user":{"displayName":"M.M.","userId":"16283090766959631234"}}},"execution_count":null,"outputs":[],"id":"TnRouNuGgbtN"},{"cell_type":"markdown","source":["So English will be our baseline to compare every category in original_language with"],"metadata":{"id":"exEp_ZHFhBsm"},"id":"exEp_ZHFhBsm"},{"cell_type":"code","source":["# Do we need to normalize runtime_in_minutes?\n","movies_cleaned2['runtime_in_minutes'].describe()"],"metadata":{"id":"8TZGvN34uy4h","executionInfo":{"status":"aborted","timestamp":1728831674079,"user_tz":-120,"elapsed":9,"user":{"displayName":"M.M.","userId":"16283090766959631234"}}},"execution_count":null,"outputs":[],"id":"8TZGvN34uy4h"},{"cell_type":"markdown","source":["### 5.1.2. Normalization of \"runtime_in_minutes\"\n","\n","The runtime_in_minutes distribution gives important insights into the data:\n","\n","Count (7758): This shows that there are 7758 movies in the dataset with a recorded runtime, which is a decent sample size.\n","\n","Mean (104): The average runtime is around 104 minutes. This suggests that most movies in the dataset are approximately 1 hour and 46 minutes long.\n","\n","Standard Deviation (19.14): The standard deviation of 19.14 minutes tells us that the runtimes vary moderately around the mean. Most movies will likely have runtimes between 85 minutes and 123 minutes (mean ± 1 standard deviation).\n","\n","Minimum (12.0): The shortest movie is only 12 minutes long, which is likely a short film or some form of special content.\n","\n","Quartiles (25th percentile: 94, 50th percentile (median): 104, 75th percentile: 117):\n","\n","25th percentile (94 minutes): 25% of the movies are shorter than 94 minutes.\n","Median (104 minutes): 50% of the movies are shorter than 104 minutes.\n","75th percentile (116 minutes): 75% of the movies are shorter than 117 minutes.\n","The interquartile range (IQR), which measures the middle 50% of runtimes, is 23 minutes (116 - 94). This indicates a fairly narrow range for most movies, implying that many movies fall between 94 and 117 minutes long.\n","\n","Maximum (254 minutes): The longest movie in the dataset is 254 minutes (over 4 hours long), which is an extreme outlier.\n","\n","Key Observations:\n","Outliers: The minimum (12 minutes) and maximum (254 minutes) suggest there are outliers in your dataset, especially at the higher end.\n","Distribution Shape: Given the quartiles and the mean, the runtime distribution seems slightly right-skewed (positively skewed), meaning there are some very long movies pushing the average higher than the median.\n","Need for Normalization: Since the range is from 12 to 254 minutes, and the standard deviation is relatively high compared to the mean, normalizing the runtime could be helpful to reduce the influence of extreme values on your linear regression model."],"metadata":{"id":"nPFSj7tMzE4h"},"id":"nPFSj7tMzE4h"},{"cell_type":"code","source":["# so we will proceed to normalizing the runtime_in_minutes using min-max scaling to reduce the impact of outliers\n","from sklearn.preprocessing import MinMaxScaler\n","\n","# Initialize Min-Max Scaler\n","scaler = MinMaxScaler()\n","\n","# Select the column to be normalized\n","movies_cleaned2['runtime_normalized'] = scaler.fit_transform(movies_cleaned2[['runtime_in_minutes']])\n","\n","# drop the null values in the column \"runtime_normalized\"\n","movies_cleaned2 = movies_cleaned2.dropna(subset=['runtime_normalized'])\n","\n","# Display a sample of the normalized data\n","print(movies_cleaned2[['runtime_in_minutes', 'runtime_normalized']].head())"],"metadata":{"id":"aCsPROHyzSfY","executionInfo":{"status":"aborted","timestamp":1728831674079,"user_tz":-120,"elapsed":9,"user":{"displayName":"M.M.","userId":"16283090766959631234"}}},"execution_count":null,"outputs":[],"id":"aCsPROHyzSfY"},{"cell_type":"markdown","source":["### 5.1.3. Should we normalize the dependent variable \"audience_score\"?"],"metadata":{"id":"Wloi-o68HIV0"},"id":"Wloi-o68HIV0"},{"cell_type":"code","source":["movies_cleaned2['audience_score'].describe()\n"],"metadata":{"id":"T_mOxbpAdcjW","executionInfo":{"status":"aborted","timestamp":1728831674079,"user_tz":-120,"elapsed":9,"user":{"displayName":"M.M.","userId":"16283090766959631234"}}},"execution_count":null,"outputs":[],"id":"T_mOxbpAdcjW"},{"cell_type":"code","source":["movies_cleaned2['audience_score'].hist()"],"metadata":{"id":"szIZJlNEdces","executionInfo":{"status":"aborted","timestamp":1728831674079,"user_tz":-120,"elapsed":9,"user":{"displayName":"M.M.","userId":"16283090766959631234"}}},"execution_count":null,"outputs":[],"id":"szIZJlNEdces"},{"cell_type":"markdown","source":["Looking at the summary statistics for audience_score:\n","\n","Count: 7,758 movies have non-missing audience_score.\n","Mean: The average score is about 63.49.\n","Std: The standard deviation is 20.30, indicating a moderate spread around the mean.\n","Min and Max: The minimum score is 0, and the maximum is 100, covering the full range of possible audience scores.\n","Quartiles:\n","25% of movies have an audience score of 48 or below.\n","50% (median) have a score of 66 or below.\n","75% of movies have a score of 80 or below.\n","Key Points:\n","The audience score distribution is not extremely skewed, as the mean and median are relatively close (63.49 vs. 66), suggesting that the data is reasonably centered around the middle.\n","The range from 0 to 100 and the standard deviation indicate variance but not extreme outliers.\n","Should We Normalize audience_score?\n","Given that the scores are within a standard range (0–100) and show no extreme skew or outliers, normalization is likely not necessary. The distribution is fairly even, so leaving it in its raw form will keep our model predictions in a more interpretable range."],"metadata":{"id":"_hVFZAC_IArC"},"id":"_hVFZAC_IArC"},{"cell_type":"markdown","source":["### 5.1.4. One-hot encoding for the variabless \"rating\" and \"original_language\""],"metadata":{"id":"II7kcd1a2q_m"},"id":"II7kcd1a2q_m"},{"cell_type":"code","source":["movies_cleaned2.columns"],"metadata":{"id":"JZ_rmbaRatyT","executionInfo":{"status":"aborted","timestamp":1728831674079,"user_tz":-120,"elapsed":9,"user":{"displayName":"M.M.","userId":"16283090766959631234"}}},"execution_count":null,"outputs":[],"id":"JZ_rmbaRatyT"},{"cell_type":"code","source":["# Step 1: Exclude unnecessary columns\n","exclude_cols = ['movie_id', 'movie_year', 'movie_title', 'critic_score', 'critic_sentiment',\n","                'audience_sentiment', 'release_year_theaters', 'release_year_streaming',\n","                'runtime_in_minutes', 'combined_score']\n","\n","# Step 2: One-hot encode categorical variables and exclude columns not being used\n","movies_encoded = pd.get_dummies(movies_cleaned2.drop(columns=exclude_cols + ['audience_score']),\n","                                columns=['rating', 'original_language'], drop_first=False)\n","\n","# Manually drop 'rating_R' and 'original_language_English' to set them as the baseline\n","movies_encoded = movies_encoded.drop(['rating_R', 'original_language_English'], axis=1)\n","\n","movies_encoded.head(50).T\n","\n","# Add 'runtime_normalized' to the dataset (it's already part of the dataframe, so no need to add it again)\n"],"metadata":{"id":"MDdakXbjdcuS","executionInfo":{"status":"aborted","timestamp":1728831674079,"user_tz":-120,"elapsed":8,"user":{"displayName":"M.M.","userId":"16283090766959631234"}}},"execution_count":null,"outputs":[],"id":"MDdakXbjdcuS"},{"cell_type":"code","source":["\n","# Look at a specific row before and after encoding\n","print(movies_cleaned2[['rating', 'original_language']].iloc[10])  # Original categorical values for row 10\n","print(movies_encoded.iloc[10])  # One-hot encoded values for row 10"],"metadata":{"id":"KORNzmRpCjcT","executionInfo":{"status":"aborted","timestamp":1728831674079,"user_tz":-120,"elapsed":8,"user":{"displayName":"M.M.","userId":"16283090766959631234"}}},"execution_count":null,"outputs":[],"id":"KORNzmRpCjcT"},{"cell_type":"code","source":["# Checking rows where the rating is PG (non-baseline)\n","print(movies_cleaned2[movies_cleaned2['rating'] == 'PG'][['rating', 'original_language']].iloc[0])\n","print(movies_encoded[movies_cleaned2['rating'] == 'PG'].iloc[0])"],"metadata":{"id":"XAamZwbTE8nf","executionInfo":{"status":"aborted","timestamp":1728831674079,"user_tz":-120,"elapsed":8,"user":{"displayName":"M.M.","userId":"16283090766959631234"}}},"execution_count":null,"outputs":[],"id":"XAamZwbTE8nf"},{"cell_type":"code","source":["# Checking rows where the original language is French (non-baseline)\n","print(movies_cleaned2[movies_cleaned2['original_language'] == 'French'][['rating', 'original_language']].iloc[0])\n","print(movies_encoded[movies_cleaned2['original_language'] == 'French'].iloc[0])"],"metadata":{"id":"ysQsfBEYFAIr","executionInfo":{"status":"aborted","timestamp":1728831674079,"user_tz":-120,"elapsed":8,"user":{"displayName":"M.M.","userId":"16283090766959631234"}}},"execution_count":null,"outputs":[],"id":"ysQsfBEYFAIr"},{"cell_type":"markdown","source":["### 5.1.5. Building the Linear Regression Model"],"metadata":{"id":"W9gIp3fq27Hj"},"id":"W9gIp3fq27Hj"},{"cell_type":"code","source":["# Add 'runtime_normalized' to the dataset (it's already part of the dataframe, so no need to add it again)\n","\n","# Step 3: Define X (Predictors) and y (Target)\n","X = movies_encoded[['runtime_normalized'] + [col for col in movies_encoded.columns if 'rating_' in col or 'original_language_' in col]]\n","y = movies_cleaned2['audience_score']\n","\n","# Step 4: Split the data into training and testing sets\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n","\n","# Step 5: Train the Linear Regression model\n","model = LinearRegression()\n","model.fit(X_train, y_train)\n","\n","# Predict and evaluate\n","y_pred = model.predict(X_test)\n","\n","# Evaluate model performance\n","mse = mean_squared_error(y_test, y_pred)\n","r2 = r2_score(y_test, y_pred)\n","\n","print('Mean Squared Error:', mse)\n","print('R-squared:', r2)\n","\n","# To find out the influence of each variable, check the coefficients\n","coefficients = pd.DataFrame(model.coef_, X.columns, columns=['Coefficient'])\n","print(coefficients)"],"metadata":{"id":"Q8fpJZ7caKj4","executionInfo":{"status":"aborted","timestamp":1728831674079,"user_tz":-120,"elapsed":8,"user":{"displayName":"M.M.","userId":"16283090766959631234"}}},"execution_count":null,"outputs":[],"id":"Q8fpJZ7caKj4"},{"cell_type":"code","source":["# Calculate the difference between actual and predicted values\n","differences = np.abs(y_test - y_pred)\n","\n","# Create a scatter plot with a color gradient based on the differences\n","plt.scatter(y_test, y_pred, c=differences, cmap='coolwarm', edgecolor='k', alpha=0.7)\n","\n","# Add a color bar to show the scale of differences\n","plt.colorbar(label='Difference between Actual and Predicted')\n","\n","# Add labels and title\n","plt.xlabel('Actual Scores')\n","plt.ylabel('Predicted Scores')\n","plt.title('Actual vs Predicted Scores (Colored by Differences)')\n","plt.show()"],"metadata":{"id":"NG6WEMQUimwc","executionInfo":{"status":"aborted","timestamp":1728831674079,"user_tz":-120,"elapsed":8,"user":{"displayName":"M.M.","userId":"16283090766959631234"}}},"execution_count":null,"outputs":[],"id":"NG6WEMQUimwc"},{"cell_type":"markdown","source":["### 5.1.6. Results"],"metadata":{"id":"PuNv-XE-3IQZ"},"id":"PuNv-XE-3IQZ"},{"cell_type":"markdown","source":["A break down of the results of our linear regression model:\n","\n","1. Mean Squared Error (MSE):\n","MSE = 1,17\n","This measures the average squared difference between the actual audience_score values and the predicted values from your model. A lower MSE indicates better performance.\n","In our case, 366.09 indicates that the model’s predictions differ from the actual audience_score by a decent amount on average. This suggests our model is not highly accurate, even though some error is expected.\n","2. R-squared (R²):\n","R² = -2.7\n","The R² explains how well our model accounts for variance in the target variable (audience_score).\n","This R² is quite low, indicating that the factors we included in the model (runtime, rating, original language) are not capturing most of the variation in audience scores. There might be other important features missing or the relationships between the variables may not be well captured by a linear model.\n","3. Coefficients of the Features:\n","The coefficients indicate the influence of each predictor on the target variable, audience_score. A positive coefficient suggests a positive relationship, while a negative coefficient suggests the opposite.\n","\n","Next, we will interpret some of the key features:\n","\n","Runtime (normalized):\n","\n","Coefficient: 7.90\n","For each unit increase in the normalized runtime, the audience score is expected to increase by around 7.9 points, assuming all other variables remain constant. Runtime has a strong positive impact on audience score.\n","\n","Rating:\n","\n","G: 11.24\n","Movies rated \"G\" are expected to have an audience score that is 11.24 points higher than movies rated \"R\" (your baseline category), all else equal.\n","NC-17: -7.11\n","Movies rated \"NC-17\" tend to have audience scores that are about 7.11 points lower than \"R\"-rated movies.\n","PG: 6.87, PG-13: 0.51, TV: 5.71, TV-14: -4.55\n","Each of these categories' coefficients indicate how much higher or lower they predict audience score compared to the baseline rating (R).\n","Original Language:\n","\n","Afrikaans: 15.75, Arabic: 11.24, Chinese: 13.40, Danish: 22.23, French: 19.11, Finnish: 32.17, etc.\n","These coefficients tell how the movie's original language influences the audience score relative to the baseline (English). For example:\n","Movies in Danish are expected to have audience scores about 22.23 points higher than English-language movies.\n","Movies in French would score about 19.11 points higher, while Finnish-language movies would score about 32.17 points higher.\n","Negative coefficients (like for Hindi: -3.75, Norwegian: -4.36) suggest those languages might lower the predicted audience score compared to English.\n","Key Insights:\n","Runtime is positively correlated with audience score, meaning longer movies tend to have higher audience scores.\n","Rating has a clear influence on audience score, with \"G\" and \"PG\" rated movies generally receiving better scores than \"R\", and \"NC-17\" movies being scored lower than \"R\".\n","Original Language also has an impact, with some languages (like Danish, French, and Finnish) positively influencing the audience score, while others (like Hindi, Norwegian) have a small negative impact.\n","Next Steps to Improve the Model:\n","Include more relevant features (e.g., critic_score, audience_sentiment, critic_sentiment, director, actor). Some of these features may have to come from other datasets found online."],"metadata":{"id":"XELQV_VLiTjx"},"id":"XELQV_VLiTjx"},{"cell_type":"markdown","source":["## 5.2. Natural Language Processing\n","Natural Language Processing (NLP) is a branch of artificial intelligence that enables computers to understand, interpret, and generate human language. Through the implementation of NLP techniques, we can analyze textual data—such as movie reviews—transforming unstructured information into actionable insights. This allows us to assess sentiment, extract themes, and gauge audience reactions, enhancing our overall understanding of viewer perceptions and preferences."],"metadata":{"id":"d7ba112b"},"id":"d7ba112b"},{"cell_type":"markdown","source":["### 5.2.1. Cleaning Quotes and Filtering Nouns and Verbs\n","The first step in our analysis involved cleaning the movie review quotes. We used the process_quotes() function to remove stop words, which are common but uninformative words such as \"the,\" \"is,\" and \"and.\" Additionally, we defined a list of words to exclude, such as general movie-related terms (e.g., \"movie,\" \"film\") and quality descriptors (e.g., \"good,\" \"bad\"). By removing these words, we focused the analysis on those words that provide deeper insight into the content and themes of the reviews.\n","\n","After cleaning, we filtered each cleaned quote to retain only nouns and verbs. This was done using part-of-speech tagging to identify words representing core ideas or actions. This allowed us to focus specifically on key themes, such as \"love,\" \"war,\" or \"acting,\" and highlight the main concepts expressed in the reviews while eliminating less important parts of speech."],"metadata":{"id":"dOl4EsyS-twu"},"id":"dOl4EsyS-twu"},{"cell_type":"code","execution_count":null,"metadata":{"id":"5ed53f95-a723-4013-95b3-7287897c675a","executionInfo":{"status":"aborted","timestamp":1728831674079,"user_tz":-120,"elapsed":8,"user":{"displayName":"M.M.","userId":"16283090766959631234"}}},"outputs":[],"source":["# Download necessary NLTK data\n","nltk.download('punkt', quiet=True)\n","nltk.download('averaged_perceptron_tagger', quiet=True)\n","nltk.download('stopwords', quiet=True)\n","\n","# Define stop words and words to exclude\n","stop_words = set(stopwords.words('english'))\n","words_to_exclude = {\n","    # General movie-related terms\n","    'movie', 'film', 'cinema', 'picture', 'flick', 'screening', 'showing',\n","\n","    # Quality descriptors\n","    'good', 'bad', 'great', 'terrible', 'excellent', 'poor', 'amazing', 'awful',\n","    'wonderful', 'horrible', 'best', 'worst', 'favorite', 'liked', 'disliked',\n","\n","    # Cinema-related terms\n","    'actor', 'actress', 'director', 'producer', 'screenplay', 'script', 'scene',\n","    'character', 'plot', 'story', 'dialogue', 'cinematography', 'soundtrack',\n","\n","    # General descriptors\n","    'interesting', 'boring', 'exciting', 'dull', 'entertaining', 'disappointing',\n","    'impressive', 'mediocre', 'overrated', 'underrated',\n","\n","    # Time-related terms\n","    'hour', 'minute', 'long', 'short',\n","\n","    # Viewing experience\n","    'watch', 'saw', 'seen', 'theater', 'cinema', 'home',\n","\n","    # Rating-related terms\n","    'star', 'rating', 'review', 'critic', 'audience',\n","\n","    # Production-related terms\n","    'budget', 'box office', 'sequel', 'remake', 'adaptation',\n","\n","    # General opinion words\n","    'think', 'thought', 'feel', 'felt', 'believe', 'opinion'\n","}\n","stop_words.update(words_to_exclude)\n","\n","def process_quote(quote):\n","    # Convert to string if it's a list\n","    if isinstance(quote, list):\n","        quote = ' '.join(quote)\n","    else:\n","        quote = str(quote)\n","\n","    # Tokenize and remove stop words and excluded words\n","    tokens = word_tokenize(quote.lower())\n","    tokens = [word for word in tokens if word.isalnum() and word not in stop_words]\n","\n","    # Perform POS tagging\n","    tagged = pos_tag(tokens)\n","\n","    # Filter for nouns and verbs\n","    filtered = [word for word, pos in tagged if pos.startswith('N') or pos.startswith('V')]\n","\n","    return ' '.join(filtered)\n","\n","def process_quotes_in_chunks(df, chunk_size=1000):\n","    processed_chunks = []\n","    total_chunks = len(df) // chunk_size + (1 if len(df) % chunk_size != 0 else 0)\n","\n","    for i in tqdm(range(0, len(df), chunk_size), total=total_chunks, desc=\"Processing chunks\"):\n","        try:\n","            chunk = df.iloc[i:i+chunk_size].copy()\n","            chunk['filtered_quotes'] = chunk['all_quotes'].apply(process_quote)\n","            processed_chunks.append(chunk)\n","            print(f\"Processed chunk {i//chunk_size + 1}/{total_chunks}\")\n","        except Exception as e:\n","            print(f\"An error occurred while processing chunk {i//chunk_size + 1}: {str(e)}\")\n","\n","    return pd.concat(processed_chunks, ignore_index=True)"],"id":"5ed53f95-a723-4013-95b3-7287897c675a"},{"cell_type":"markdown","source":["### 5.2.2. Word Cloud of Themes\n","\n","To visualize the most common themes discussed in the movie reviews, we generated a word cloud. The word cloud was created using the cleaned dataset to present an intuitive overview of frequently mentioned topics. By emphasizing the prominent words, it gives a clear picture of what audiences and critics frequently focus on when evaluating movies."],"metadata":{"id":"abZfisiHibUx"},"id":"abZfisiHibUx"},{"cell_type":"code","execution_count":null,"metadata":{"id":"ee2f1b2f-178b-4f8b-a7ef-ad6060ef1506","executionInfo":{"status":"aborted","timestamp":1728831674080,"user_tz":-120,"elapsed":9,"user":{"displayName":"M.M.","userId":"16283090766959631234"}}},"outputs":[],"source":["# Load the processed data\n","\n","import gdown\n","import pandas as pd\n","\n","# Google Drive file ID for the \"processed_movie_quotes.csv\" file\n","file_id = '1pPXkjjZaYkFFLShvgCUG53yILh9_SW04'\n","\n","# Import the \"processed_movie_quotes.csv\" file using gdown\n","gdown.download(f'https://drive.google.com/uc?export=download&id={file_id}', 'processed_movie_quotes.csv', quiet=True)\n","\n","# Load the downloaded \"processed_movie_quotes.csv\" file into a pandas DataFrame\n","df = pd.read_csv('processed_movie_quotes.csv')\n","\n","# Replace NaN with an empty string and convert all values to strings\n","df['filtered_quotes'] = df['filtered_quotes'].fillna('').astype(str)\n","\n","# Remove any empty strings\n","df = df[df['filtered_quotes'] != '']\n","\n","print(\"Number of rows after cleaning:\", len(df))"],"id":"ee2f1b2f-178b-4f8b-a7ef-ad6060ef1506"},{"cell_type":"code","execution_count":null,"metadata":{"id":"9a98be7a-1719-4681-845e-a6a72c2bc1ca","executionInfo":{"status":"aborted","timestamp":1728831674080,"user_tz":-120,"elapsed":9,"user":{"displayName":"M.M.","userId":"16283090766959631234"}}},"outputs":[],"source":["# Function to process quotes in chunks\n","def process_quotes_chunk(chunk):\n","    return Counter(' '.join(chunk).split())\n","\n","# Load and process data in chunks\n","chunk_size = 1000  # Adjust based on your system's capacity\n","word_freq = Counter()\n","\n","print(\"Processing quotes in chunks...\")\n","start_time = time.time()\n","\n","for chunk in (df[i:i + chunk_size] for i in range(0, len(df), chunk_size)):\n","    chunk['filtered_quotes'] = chunk['filtered_quotes'].fillna('').astype(str)\n","    chunk = chunk[chunk['filtered_quotes'] != '']\n","    word_freq.update(process_quotes_chunk(chunk['filtered_quotes']))\n","\n","    # Clear some memory\n","    del chunk\n","    gc.collect()\n","\n","end_time = time.time()\n","print(f\"Time taken to process all chunks: {end_time - start_time:.2f} seconds\")\n","\n","# Keep only words that appear more than a certain number of times\n","min_freq = 10\n","frequent_words = {word: count for word, count in word_freq.items() if count > min_freq}\n","\n","print(f\"Total unique words: {len(word_freq)}\")\n","print(f\"Words appearing more than {min_freq} times: {len(frequent_words)}\")\n","\n","# Create a word cloud\n","def create_word_cloud(word_freq):\n","    wordcloud = WordCloud(width=1600, height=800,\n","                          background_color='white',\n","                          max_words=500,\n","                          relative_scaling=0.5).generate_from_frequencies(word_freq)\n","    plt.figure(figsize=(20, 10))\n","    plt.imshow(wordcloud, interpolation='bilinear')\n","    plt.axis('off')\n","    plt.title('Word Cloud of Movie Quotes (Full Dataset)')\n","    plt.show()\n","\n","# Generate word cloud\n","print(\"Generating word cloud...\")\n","start_time = time.time()\n","create_word_cloud(frequent_words)\n","end_time = time.time()\n","\n","print(f\"Time taken to generate word cloud: {end_time - start_time:.2f} seconds\")"],"id":"9a98be7a-1719-4681-845e-a6a72c2bc1ca"},{"cell_type":"code","execution_count":null,"metadata":{"id":"b6e3a36a-5862-4ccf-9794-cd4ef440c6e2","executionInfo":{"status":"aborted","timestamp":1728831674080,"user_tz":-120,"elapsed":9,"user":{"displayName":"M.M.","userId":"16283090766959631234"}}},"outputs":[],"source":["# Separate good and bad movies\n","median_score = df['average_combined_score'].median()\n","good_movies = df[df['average_combined_score'] > median_score]\n","bad_movies = df[df['average_combined_score'] <= median_score]\n","\n","# Create bigram vectorizer\n","vectorizer = CountVectorizer(ngram_range=(2,2), stop_words='english')\n","\n","# Get bigrams for good and bad movies\n","good_bigrams = vectorizer.fit_transform(good_movies['filtered_quotes'])\n","bad_bigrams = vectorizer.transform(bad_movies['filtered_quotes'])\n","\n","# Calculate ratio of frequencies\n","good_freq = good_bigrams.sum(axis=0).A1\n","bad_freq = bad_bigrams.sum(axis=0).A1\n","ratio = np.log((good_freq + 1) / (bad_freq + 1))\n","\n","# Get feature names\n","feature_names = vectorizer.get_feature_names_out()\n","\n","# Sort by ratio and get top distinctive bigrams\n","top_good = sorted(zip(feature_names, ratio), key=lambda x: -x[1])[:20]\n","top_bad = sorted(zip(feature_names, ratio), key=lambda x: x[1])[:20]\n","\n","print(\"Bigrams more associated with good movies:\")\n","print(', '.join([f'\"{bg}\"' for bg, _ in top_good]))\n","\n","print(\"\\nBigrams more associated with bad movies:\")\n","print(', '.join([f'\"{bg}\"' for bg, _ in top_bad]))"],"id":"b6e3a36a-5862-4ccf-9794-cd4ef440c6e2"},{"cell_type":"code","execution_count":null,"metadata":{"id":"7d3e54fa-9ec2-46bb-9af7-7c70a1c33a7c","executionInfo":{"status":"aborted","timestamp":1728831674080,"user_tz":-120,"elapsed":9,"user":{"displayName":"M.M.","userId":"16283090766959631234"}}},"outputs":[],"source":["# Set this to True to create word clouds\n","CREATE_WORD_CLOUD = True\n","CUSTOM_STOPWORDS = set([\n","    # General filler words that do not add distinctiveness\n","    'get', 'got', 'make', 'made', 'see', 'go', 'going', 'take', 'want', 'know',\n","    'look', 'find', 'remember', 'came', 'come', 'comes', 'getting', 'done',\n","    'trying', 'need', 'kept', 'work', 'used', 'went', 'felt',\n","    'little', 'big', 'best', 'good', 'fun', 'lot', 'lots', 'thing', 'things',\n","    'everything', 'anything', 'nothing', 'play', 'played', 'plays', 'playing',\n","    'part', 'parts', 'left', 'end', 'ending', 'line', 'based', 'version',\n","    'sort', 'kind', 'seem', 'seems', 'feels', 'felt', 'place', 'places',\n","    'wait', 'waiting', 'given', 'giving', 'took', 'turn', 'turns',\n","    'moment', 'moments', 'viewing', 'john', 'stars', 'effects', 'keep',\n","    'lines', 'story', 'plot', 'told', 'tell', 'telling', 'seen',\n","    'sense', 'coming', 'couple', 'shows', 'piece', 'moving', 'mind', 'style',\n","    'hate', 'lol', 'looking', 'hell', 'kid', 'night', 'game', 'jokes', 'kinda', 'wanted',\n","    'stuff', 'let', 'girl', 'looks', 'b', 'hate', 'kid', 'night', 'movies', 'thriller', 'humor',\n","    'lol', 'expect', 'tv', 'recommend', 'fans', 'someone', 'care', 'school', 'ass', 'death', 'start',\n","    'michael', 'twist', 'seemed', 'rest', 'money', 'house', 'beginning', 'la',\n","    'works', 'try', 'lost', 'others', 'genre', 'concept', 'guess', 'premise', 'expecting', 'creepy',\n","    'jason', 'act', 'sex', 'animation', 'score', 'experience', 'written', 'hollywood', 'directed',\n","    'brilliant', 'camera', 'violence', 'fight', 'hope', 'gave', 'read', 'understand', 'god', 'face', 'children',\n","\n","    # General and evaluative terms without specific value\n","    'movies', 'time', 'way', 'characters', 'acting', 'scenes', 'cast', 'times',\n","    'something', 'watched', 'actors', 'role', 'makes', 'say', 'book', 'series', 'films',\n","    'performance', 'performances', 'job', 'music', 'fun', 'enjoyed', 'history', 'war',\n","    'action', 'drama', 'gets', 'bit', 'enjoy', 'half', 'reason', 'fact', 'idea', 'script',\n","    'scene', 'scenes', 'storyline', 'director', 'help', 'anyone', 'gives', 'course',\n","\n","    # Evaluative words without context\n","    'oscar', 'masterpiece', 'genius', 'epic', 'superb', 'perfect', 'stunning',\n","    'crap', 'shit', 'waste', 'beautiful', 'annoying', 'cheesy', 'great', 'funny', 'awesome',\n","    'fantastic', 'bad', 'terrible', 'awful', 'wonderful', 'amazing', 'interesting',\n","\n","    # Overly broad descriptors\n","    'man', 'woman', 'people', 'guys', 'girls', 'family', 'kids', 'ladies', 'men', 'friends',\n","    'today', 'life', 'years', 'days', 'day', 'minutes', 'hours', 'age',\n","    'cool', 'laugh', 'laughs', 'laughing', 'smile', 'cute', 'nice',\n","\n","    # Words without distinctive value in quality differentiation\n","    'love', 'loved', 'comedy', 'horror', 'guy', 'everyone', 'show', 'fan', 'seeing',\n","    'making', 'point', 'found', 'expected', 'said', 'give', 'put', 'takes',\n","    'set', 'goes', 'year', 'heart', 'watching', 'world', 'direction', 'que', 'disney',\n","\n","    # Additional words to add to CUSTOM_STOPWORDS:\n","    'franchise', 'james', 'tom', 'smith',\n","    'problem', 'thinking', 'sequences', 'dont', 'better', 'jim',\n","    'rock', 'kill', 'car', 'head', 'happened', 'use', 'person', 'ones',\n","    'critics', 'save', 'keeps', 'stop', 'tries', 'message', 'points',\n","    'supposed', 'stories', 'entertainment', 'starts', 'looked', 'started',\n","    'okay', 'son', 'turned', 'kevin', 'landmark', 'oscars', 'division',\n","    'firefly', 'pianist', 'mean', 'sucked', 'needed', 'worth', 'fucking',\n","    'hated', 'disturbing', 'ok', 'sucks', 'laughed', 'happens', 'saying',\n","    'needs', 'wants', 'taking', 'leave', 'cry', 'called', 'becomes', 'happen',\n","    'run', 'gon', 'says', 'falls', 'become', 'taking', 'case', 'side', 'ways',\n","    'gene', 'hitler', 'mozart', 'gandhi', 'brandon', 'howl', 'dean',\n","    'grail', 'marx', 'salieri', 'kinski', 'hawks', 'lamotta', 'atticus',\n","    'timeless', 'sunset', 'sunrise', 'boxing', 'ewoks', 'bjork',\n","    'plainview', 'gael', 'spaghetti', 'attention', 'feeling', 'roles', 'type',\n","    'name', 'thats', 'eyes',\n","    'ends', 'hit', 'screen', 'move', 'cut', 'voice', 'ended', 'team',\n","    'e', 'interest', 'cause', 'dance', 'taken', 'es', 'friend',\n","    'elements', 'check', 'center', 'yes', 'knew', 'gangster', 'western', 'python', 'noir',\n","    'mob', 'guinness', 'raging',\n","    'criterion', 'vietnam', 'falcon', 'fargo', 'murrow', 'maude', 'harvey',\n","    'spirited', 'strangelove', 'cagney', 'bueller', 'travis', 'bueller',\n","    'rwanda', 'mcmurphy', 'falcon', 'landau', 'pekars',  'altman', 'stanley', 'criterion',\n","    'criterion', 'criterion', 'fargo',\n","    'musicals', 'technicolor', 'indemnity', 'masterpieces', 'barton',\n","    'searchers', 'louise', 'rains', 'vienna', 'serenity', 'vito', 'pesci',\n","    'braddock', 'kane', 'katharine', 'cleef', 'benigni', 'vivien',\n","    'andrews', 'sergio', 'benigni', 'andrews', 'toshio',\n","    'writing', 'die', 'stand', 'bring', 'alot', 'visuals', 'killed', 'wife',\n","    'yeah', 'delivers', 'harry', 'lack', 'development', 'child', 'mark',\n","    'change', 'video', 'chris', 'brings',\n","    'img', 'decent', 'quality', 'dvd', 'surprise', 'scares', 'da', 'ideas',\n","    'matter', 'damn', 'fell', 'villain', 'production', 'lead', 'casting',\n","    'leads', 'expectations', 'relationship', 'ride', 'knows', 'effort',\n","    'songs', 'parents', 'means', 'admit', 'fighting', 'dog', 'jackson',\n","    'bill', 'please', 'attempt', 'lacks', 'dark', 'events', 'group', 'pretty',\n","    'wonder', 'mess', 'level', 'pero', 'fails', 'song', 'wests', 'mcmurpow',\n","    'chick', 'women', 'adam', 'boy', 'king', 'didnt',\n","\n","])\n","\n","\n","# Set this to True to create word clouds\n","CREATE_WORD_CLOUD = True\n","\n","# Combine with standard stopwords\n","ALL_STOPWORDS = set(STOPWORDS).union(CUSTOM_STOPWORDS)\n","\n","OPWORDS = set(STOPWORDS).union(CUSTOM_STOPWORDS)\n","\n","# Tokenizer to use for both positive and negative reviews\n","tokenizer = re.compile(r'\\b\\w+\\b')\n","\n","def process_data_in_chunks(file_path, chunk_size=1000):\n","    positive_counter = Counter()\n","    negative_counter = Counter()\n","    median_score = None\n","    total_rows = 0\n","\n","    print(\"Calculating median score...\")\n","    start_time = time.time()\n","    for chunk in pd.read_csv(file_path, chunksize=chunk_size, encoding='utf-8'):\n","        chunk = chunk[chunk['filtered_quotes'].notna() & (chunk['filtered_quotes'] != '')]\n","        total_rows += len(chunk)\n","        if median_score is None:\n","            median_score = chunk['average_combined_score'].median()\n","\n","    print(f\"Median score: {median_score}\")\n","    print(f\"Total rows: {total_rows}\")\n","    print(f\"Time taken to calculate median: {time.time() - start_time:.2f} seconds\")\n","\n","    print(\"Processing quotes...\")\n","    start_time = time.time()\n","\n","    with tqdm(total=total_rows, unit='row') as pbar:\n","        for chunk in pd.read_csv(file_path, chunksize=chunk_size, encoding='utf-8'):\n","            chunk = chunk[chunk['filtered_quotes'].notna() & (chunk['filtered_quotes'] != '')]\n","\n","            positive_chunk = chunk[chunk['average_combined_score'] > median_score]['filtered_quotes']\n","            negative_chunk = chunk[chunk['average_combined_score'] <= median_score]['filtered_quotes']\n","\n","            # Use the same tokenizer for both positive and negative quotes\n","            positive_counter.update(word.lower() for quote in positive_chunk for word in tokenizer.findall(quote) if word.lower() not in ALL_STOPWORDS)\n","            negative_counter.update(word.lower() for quote in negative_chunk for word in tokenizer.findall(quote) if word.lower() not in ALL_STOPWORDS)\n","\n","            pbar.update(len(chunk))\n","\n","            del chunk, positive_chunk, negative_chunk\n","            gc.collect()\n","\n","    print(f\"Time taken to process quotes: {time.time() - start_time:.2f} seconds\")\n","    return positive_counter, negative_counter\n","\n","def compare_word_frequencies(counter1, counter2):\n","    word_diff = Counter()\n","    for word in set(counter1.keys()).union(counter2.keys()):\n","        word_diff[word] = counter1.get(word, 0) - counter2.get(word, 0)\n","    return word_diff\n","\n","def create_word_cloud(counter, title):\n","    if not CREATE_WORD_CLOUD:\n","        print(\"Word cloud creation is disabled.\")\n","        return\n","\n","    try:\n","        print(f\"Generating word cloud for {title}...\")\n","        # Adjust the parameters to ensure all words are visible\n","        wordcloud = WordCloud(\n","            width=800,\n","            height=400,\n","            background_color='white',\n","            max_words=200,  # Increase to include more words\n","            relative_scaling=0.5,  # Adjust scaling to give less frequent words a better chance\n","            min_font_size=5,  # Ensure smaller words are still displayed\n","            stopwords=set()  # Avoid automatic filtering\n","        ).generate_from_frequencies(counter)\n","\n","        plt.figure(figsize=(10, 5))\n","        plt.imshow(wordcloud, interpolation='bilinear')\n","        plt.axis('off')\n","        plt.title(title)\n","        plt.show()\n","        plt.close()\n","        print(f\"Word cloud for {title} has been displayed.\")\n","    except Exception as e:\n","        print(f\"Failed to generate word cloud for {title}. Error: {e}\")\n","\n","def create_filtered_counter(word_diff, condition='positive', top_n=100):\n","    filtered_counter = Counter()\n","    if condition == 'positive':\n","        filtered_words = {word: diff for word, diff in word_diff.items() if diff > 0}\n","    elif condition == 'negative':\n","        filtered_words = {word: -diff for word, diff in word_diff.items() if diff < 0}\n","    else:\n","        raise ValueError(\"Condition must be either 'positive' or 'negative'\")\n","\n","    # Sort and get the top_n words\n","    top_words = dict(sorted(filtered_words.items(), key=lambda x: -x[1])[:top_n])\n","    filtered_counter.update(top_words)\n","    return filtered_counter\n","\n","def print_distinctive_words(counter, title):\n","    distinctive_words = list(counter.keys())\n","    print(f\"\\nDistinctive words for {title}:\")\n","    print(\", \".join(distinctive_words))\n","\n","# Main execution (updated for clarification)\n","start_time = time.time()\n","positive_counter, negative_counter = process_data_in_chunks(df)\n","\n","print(\"Comparison with stopwords:\")\n","word_diff = compare_word_frequencies(positive_counter, negative_counter)\n","\n","# Create filtered counters for distinctive words\n","distinctive_positive_counter = create_filtered_counter(word_diff, condition='positive', top_n=50)\n","distinctive_negative_counter = create_filtered_counter(word_diff, condition='negative', top_n=50)\n","\n","# Print the distinctive words for your reference\n","print_distinctive_words(distinctive_positive_counter, \"Highly-Rated Movies\")\n","print_distinctive_words(distinctive_negative_counter, \"Poorly-Rated Movies\")\n","\n","# Generate word clouds for distinctive positive and negative words\n","if CREATE_WORD_CLOUD:\n","    create_word_cloud(distinctive_positive_counter, 'Word Cloud of Distinctive Words in Highly-Rated Movies')\n","    create_word_cloud(distinctive_negative_counter, 'Word Cloud of Distinctive Words in Poorly-Rated Movies')\n","\n","# Clear memory\n","del positive_counter, negative_counter\n","gc.collect()\n","\n","print(f\"Total execution time: {time.time() - start_time:.2f} seconds\")\n","print(\"Script completed. Check the console output for results and any generated word clouds.\")"],"id":"7d3e54fa-9ec2-46bb-9af7-7c70a1c33a7c"},{"cell_type":"code","execution_count":null,"metadata":{"id":"c08cddce-c205-4761-a65e-cd554412ccaa","executionInfo":{"status":"aborted","timestamp":1728831674080,"user_tz":-120,"elapsed":9,"user":{"displayName":"M.M.","userId":"16283090766959631234"}}},"outputs":[],"source":["# Your top 20 word lists\n","highly_rated_top_20 = [\n","    'miyazaki', 'hepburn', 'pacino', 'hitchcock', 'kubrick', 'kurosawa',\n","    'leone', 'bogart', 'chaplin', 'brando', 'goodfellas', 'godfather',\n","    'wilder', 'stewart', 'welles', 'bergman', 'anime', 'coen',\n","    'almodovar', 'newman'\n","]\n","\n","poorly_rated_top_20 = [\n","    'bond', 'sandler', 'cage', 'cruise', 'twists', 'gore', 'blood',\n","    'chemistry', 'zombie', 'williams', 'killer', 'romance', 'cgi',\n","    'vampire', 'carrey', 'adventure', 'murphy', 'surprised',\n","    'sequels', 'suspense', 'confusing'\n","]\n","\n","# Create Counter objects for the word cloud\n","highly_rated_counter = Counter({word: 1 for word in highly_rated_top_20})\n","poorly_rated_counter = Counter({word: 1 for word in poorly_rated_top_20})\n","\n","# Generate word clouds\n","create_word_cloud(highly_rated_counter, 'Word Cloud of Distinctive Words in Highly-Rated Movies')"],"id":"c08cddce-c205-4761-a65e-cd554412ccaa"},{"cell_type":"code","source":["create_word_cloud(poorly_rated_counter, 'Word Cloud of Distinctive Words in Poorly-Rated Movies')"],"metadata":{"id":"fJsqbN15oHbp","executionInfo":{"status":"aborted","timestamp":1728831674080,"user_tz":-120,"elapsed":9,"user":{"displayName":"M.M.","userId":"16283090766959631234"}}},"id":"fJsqbN15oHbp","execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### 5.2.3. NLP Results\n","\n","The most distinctive words in highly-rated movies included notable directors like \"Miyazaki\" and \"Hitchcock\" as well as iconic actors like \"Pacino\" and \"Hepburn.\" These names suggest that well-known talents significantly contribute to a movie's success. On the other hand, poorly-rated movies had themes like \"gore,\" \"zombie,\" and \"sequels,\" indicating that certain genres or types of movies tend to receive more critical reviews.\n","\n","Insights:\n","- Highly-Rated Movies: The distinctive words associated with highly-rated movies included notable names such as \"Miyazaki,\" \"Hitchcock,\" \"Kubrick,\" and \"Bergman.\" This suggests that acclaimed directors and actors are frequently linked to movies that perform well. Themes like \"anime\" and \"coen\" indicate that certain genres or production styles resonate positively with audiences.\n","\n","- Poorly-Rated Movies: The most distinctive words for poorly-rated movies included \"sandler,\" \"cage,\" \"gore,\" and \"zombie.\" These words suggest that movies featuring certain actors or focusing on specific genres, such as horror, are more likely to receive critical reviews. Words like \"sequels\" and \"twists\" also imply that poorly-executed plot twists or over-reliance on sequels may contribute to lower ratings.\n","\n","These insights help us understand the elements that audiences and critics find appealing or off-putting, providing valuable guidance for movie creators looking to enhance their content and reach wider acclaim."],"metadata":{"id":"tohlywzmoLlb"},"id":"tohlywzmoLlb"},{"cell_type":"markdown","source":["## 6. Conclusion"],"metadata":{"id":"51b8cd84"},"id":"51b8cd84"},{"cell_type":"markdown","source":["This project has been an insightful exploration into the world of data, with significant tasks undertaken and key topics examined in depth. The work demonstrates advanced techniques in data cleaning, manipulation, and visualization. Functions were employed to optimize the code, reducing redundancy and improving overall readability. The data visualization component provided clear and immediate insights into the most popular movies in the industry, utilizing interactive graphs to enhance the presentation and efficiently manage space.\n","\n","The \"Data Science\" section highlighted the power of analytical methods in uncovering patterns that are applicable to real-world scenarios.\n","\n","Furthermore, merging multiple datasets into a cohesive whole was a key element of the project, showcasing an important skill in data analysis. This merged dataset was effectively used in the NLP section to analyze both critic and user reviews, delivering valuable insights into sentiment and opinion within the movie industry."],"metadata":{"id":"WSQauaWKOy6v"},"id":"WSQauaWKOy6v"}],"metadata":{"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.7"},"colab":{"provenance":[]}},"nbformat":4,"nbformat_minor":5}